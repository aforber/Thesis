---
title: "A comparison of statistical methods for improving rare event classification in medicine"
subtitle: "Thesis Defense"
author:  |
 | Alyssa Forber
 | April 18th 2018
date: |
  | Colorado School of Public Health
  | University of Colorado, Anschutz Medical Campus
  | Department of Biostatistics
output:
  beamer_presentation: default
  slidy_presentation: default
theme: Boadilla
colortheme: seahorse
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
## Outline


Problem

Objectives

Methods

Case Studies

Simulation Study

Discussion

Conclusion


## Imbalanced Learning Problem

- Predictive models learn poorly when datasets are imbalanced
- Over learning the majority and under learning the minority
- Results in low sensitivity and high specificity
- Need to improve predictive performance

- Many examples in medicine, diseases or adverse reactions taking place in small percent of the population


## Aims


- Improve predictive performance for imbalanced dataset
- Utilizing measures of sensitivity, specificity, accuracy, and ROC analysis to evaluate performance
- Use and compare two methods to handle imbalance
    - Informed probability cutpoints for predicted probabilities
    - Sampling techniques to balance datasets
- Evaluate methods to recommend approaches in medicine


## Methods

- Split data into training and test sets

- Create balanced datasets through sampling on test set

- Run predictive model on sampled data

- Get predicted probabilities on the hold-out test data

- Optimize probability cutoff for outcome


## Model 

Cross-validated lasso regression
  - Least Absolute Shrinkage and Selection Operator

- Lasso:
    - Shrinks estimates by penalizing size of coefficients
    - Performs variable selection by shrinking some to 0
    
    
$$\hat\beta_{lasso}= argmin \sum_{j=1}^{N}(y_i-\beta_0-\sum_{j=1}^{p}x_{ij}\beta_j)^2 $$

subject to $\sum_{j=1}^p |\beta_j| \leq t$ where $t$ is the tuning parameter. 
    
## Cross Validation

- Cross validation: 
    - Find the best "tuning measure" for model selection which determines amount of shrinkage of estimates
    - Split data into k parts and then train on each of those except one you validate against
    - Then pick the tuning measure that minimizes error
    
![K fold cross validation](/Users/alyssaforber/Documents/Denver/Thesis/Figures/cross_val.jpeg){ width=60% }

## Advantages and Disadvantages


- Advantages:
    - Lower variance of the predicted values
    - More accurate predictions
    - Reduces the number of predictors

- Disadvantages:
    - Biased coefficients, inference not same as logistic regression
    - No standard errors or p-values out of the model



## ROC & Cutoff Probabilities

ROC (with pROC package):

- Receiver Operating Characteristics
- ROC curve plots sensitivity vs specificity
- Each point on curve corresponds to a decision cutoff
- Youden's Index calculated the furthest upper left corner or "max" on curve 
- Area under the curve (AUC) should be maximized


## ROC Curve


![ROC Curve](/Users/alyssaforber/Box Sync/AlyssaKatieResearch/Opioids/Results/ExampleROC.png){ width=60% }

    
## Confusion Matrix
\begin{columns}
\begin{column}{0.58\textwidth}

\textbf{Correctly identify those w/ outcome:}
$$ Sensitivity = \frac{TP}{TP+FN}$$

\textbf{Correctly identify those w/o outcome:}
$$ Specificity = \frac{TN}{TN+FP}$$

\textbf{Correctly identify either group:}
$$ Accuracy = \frac{TP+ TN}{TP+FP+TN+FN}$$

\end{column}
\begin{column}{0.42\textwidth}

\includegraphics[width=5cm]{/Users/alyssaforber/Documents/Denver/Thesis/Figures/confusion_matrix.png}

\end{column}
\end{columns}


## First Approach

No Sampling, Optimize Cut-off:

- Use original unsampled data and get predictions from the lasso model
    - Predictions return probability between 0 and 1 for each observation

- Use 0.5 standard probability cutoff to compare

- Find "best" probability cutoff
      - Youden's Index


## Second Approach

Sampling:

- Create sampled data sets that are balanced 
    - Down sample
    - Up sample
    - SMOTE

- Predict and use Youden's Index as cutoff


## Down Sampling

- Under-sample majority to equal minority

![Down sample](/Users/alyssaforber/Documents/Denver/Thesis/Figures/undersampling.png){ width=60% }

## Up Sampling

- Over-sample minority to equal majority

![Up sample](/Users/alyssaforber/Documents/Denver/Thesis/Figures/oversampling.png){ width=60% }
        
## SMOTE

- Synthetic Minority Over-sampling Technique

![SMOTE](/Users/alyssaforber/Documents/Denver/Thesis/Figures/smote.jpg){ width=60% }
 
## Models

- Model 1: No Sampling
    - 0.5 cutoff 
    - Youden's Index

- Model 2: Down Sampling
    - Youden's Index

- Model 3: Up Sampling
    - Youden's Index

- Model 4: SMOTE
    - Youden's Index

## Case Studies

We used these methods on two case studies to see how results may differ between two real world examples with rare outcomes.

- Case Study 1: Predicting chronic opioid therapy in hospitalized patients (5%)

- Case Study 2: Predicting surgical site infections in hospitalized patients (3.4%)

## Case Study 1

- Data from Denver Health electronic health records (EHR) 
- Definition of Chronic Opioid Therapy (COT) one year following the index hospital discharge:

> Receipt of $\geq$ 90-day supply of opioids with < 30-day gap in supply over a 180-day period or receipt of $\geq$ 10 opioid prescriptions over one year. 

- 27,705 patients where 5% developed COT within a year
- 35 explanatory variables 
    - Ex: age, race, history of chronic pain, discharge diagnosis

        
## Case Study 1: Results


\begin{table}
\centering
\caption {Results for Chronic Opioid Therapy} 
\scalebox{0.65}{
\begin{tabular}{l c c c c c c c c}
\hline
\textbf{Model} & \textbf{Threshold} & \textbf{Sensitivity} & \textbf{Specificity} & \textbf{NPV} & \textbf{PPV} & \textbf{Accuracy} & \textbf{AUC}  & \textbf{Covariates}\\
\hline
\textbf{Unsampled 0.5} & 0.5 & 8 & 99	& 96 & 35 & 96 & 86 & 31  \\
\textbf{Unsampled} & 0.043 &	85 & 73 & 99	& 12 & 73	& 86 & 31\\
\textbf{Down sampled} & 0.401	& 85	& 73 & 99 & 12 & 74 & 86 & 34\\
\textbf{Up sampled} & 0.399	& 85	& 74 & 99 & 12	& 74 & 87  & 34 \\
\textbf{SMOTE} & 0.472 & 74	& 84 & 99 & 17 & 84 & 86  & 33 \\
\hline
\end{tabular}
}
\end{table}


## ROC Plot

![ROC for Original Data: Youden's Index and 0.5 cutoffs](/Users/alyssaforber/Box Sync/AlyssaKatieResearch/Opioids/Results/LassROCplot.png){ width=60% }


## Case Study 2

- Need to identity post-operative complications without the use of manual chart reviews by nurses
- Surgical site infections (SSI) are the most common complication
- \>50% of SSIs occur after patient discharge
- Data from 6,840 patients at the University of Colorado Hospital from 2013-2016
- 136 independent variables were all binary indicators 
    - Ex: Antibiotic prescriptions, procedure codes, ICD-9 codes


## Case Study 2: Results


\begin{table}
\centering
\caption {Results for Surgical Site Infections} 
\scalebox{0.65}{
\begin{tabular}{l c c c c c c c c}
\hline
\textbf{Model} & \textbf{Threshold} & \textbf{Sensitivity} & \textbf{Specificity} & \textbf{NPV} & \textbf{PPV} & \textbf{Accuracy} & \textbf{AUC}  & \textbf{Covariates}\\
\hline
\textbf{Unsampled 0.5} & 0.50 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
\textbf{Unsampled} & 0.04 & 80 & 90 & 99 & 24 & 90 & 89 & 35 \\
\textbf{Down sampled} & 0.48 & 82 & 87 & 99 & 20 & 87 & 89 & 20 \\
\textbf{Up sampled} & 0.45 & 79 & 91 & 99 & 24 & 90 & 89 & 123 \\
\textbf{SMOTE} & 0.15 & 89 & 79 & 99 & 14 & 80 & 88 & 88 \\
\hline
\end{tabular}
}
\end{table}

## Simulation Study 

- We conducted a simulation study to look at how to methods performed at a greater range of prevalences

- We chose 3%, 5%, 10%, 20%, 40%, and 50% outcomes

- Goals:
    - Evaluate performance differences
    - Determine at what point it's no longer necessary to worry about imbalance

## Simulation Methods

- Selected 10 of the strongest predictors to run a logistic regression
- Set the results as the values for the coefficients for the linear predictor
- Simulated the new outcome with a logistic distribution $$F(x) = \frac{e^z}{1+e^z}$$
- Controlled prevalence by adjusting the intercept 
- Implemented sampling and lasso regression with additional 15 predictors (30 total) to get results


## Simulation Results Part 1

\begin{table}[]
\centering
\caption{Results for 3, 5 and 10\%}
\label{my-label}
\scalebox{0.73}{
\begin{tabular}{lcccccc}
\hline
             & Threshold & Sensitivity & Specificity & Accuracy & AUC & Coefficients \\
\hline
\textbf{3\%}          &     &       &        &        &     &              \\
Unsampled 0.5 & 0.50     & 2     & 100         & 97       & 79  & 6            \\
Unsampled    & 0.03      & 70    & 75          & 74       & 79  & 6            \\
Down Sampled & 0.49      & 70     & 74          & 74       & 78  & 9            \\
Up Sampled   & 0.48      & 70     & 74          & 74       & 78  & 27           \\
SMOTE        & 0.41      & 70    & 74          & 74       & 78  & 15           \\
\hline
\textbf{5\%}          &         &       &        &          &     &              \\
Unsampled 0.5 & 0.50      & 4     & 100         & 95       & 78  & 7            \\
Unsampled    & 0.05      & 69     & 74          & 74       & 78  & 7            \\
Down Sampled & 0.49      & 69     & 74          & 74       & 78  & 9            \\
Up Sampled   & 0.49      & 69     & 74          & 74       & 78  & 23           \\
SMOTE        & 0.41      & 69     & 74          & 74       & 78  & 16           \\
\hline
\textbf{10\%}         &         &      &        &          &     &              \\
Unsampled 0.5 & 0.50      & 8     & 100         & 91       & 77  & 8            \\
Unsampled    & 0.10      & 68     & 74          & 73       & 77  & 8            \\
Down Sampled & 0.49      & 68     & 74          & 73       & 77  & 9            \\
Up Sampled   & 0.49      & 68     & 74          & 73       & 77  & 18           \\
SMOTE        & 0.42      & 68     & 73          & 73       & 77  & 19           \\
\hline
\end{tabular}
}
\end{table}


## Simulations Results Part 2

\begin{table}[]
\centering
\caption{Results for 20, 40, and 50\%}
\label{my-label}
\scalebox{0.75}{
\begin{tabular}{lcccccc}
\hline
             & Threshold & Sensitivity & Specificity & Accuracy & AUC & Coefficients \\
\hline
\textbf{20\%}   &     &       &       &     &     &            \\
Unsampled 0.5 & 0.50    & 21       & 97      & 82      & 76  & 8          \\
Unsampled    & 0.20      & 66      & 73      & 72     & 76   & 8          \\
Down Sampled & 0.49      & 66      & 73     & 72       & 76  & 9            \\
Up Sampled   & 0.49      & 66      & 73     & 72       & 76  & 13           \\
SMOTE        & 0.42      & 66     & 72      & 71       & 75  & 23           \\
\hline
\textbf{40\%}        &     &      &        &          &     &              \\
Unsampled 0.5 & 0.50      & 49    & 84          & 70       & 74  & 9            \\
Unsampled    & 0.39      & 66     & 71          & 69       & 74  & 9            \\
Down Sampled & 0.49      & 66     & 71          & 69       & 74  & 9            \\
Up Sampled   & 0.49      & 65     & 71          & 69       & 74  & 10           \\
SMOTE        & 0.41      & 64     & 71          & 68       & 73  & 28           \\
\hline
\textbf{50\%}         &     &        &        &        &     &              \\
Unsampled 0.5 & 0.50      & 63    & 72          & 68       & 73  & 9            \\
Unsampled    & 0.49      & 63    & 72          & 68       & 73  & 9            \\
\hline
\end{tabular}
}
\end{table}

## Sensitivity and Specificty by Prevalence

![Comparing Youden's Index vs 0.5 cutoff results across prevalence](/Users/alyssaforber/Documents/Denver/Thesis/Results/Plots/SensSpec_Prev_20180407.png){ width=70% }

## Youden's Index by Prevalence

![Youden's Index matches prevalence](/Users/alyssaforber/Documents/Denver/Thesis/Results/Plots/Thresh_Prev_20180406.png){ width=60% }

## Discussion

- Not much difference between Youden's + sampling vs. Youden's alone
- Over sampling and SMOTE had highest number of coefficients
- Threshold equals prevalence 
- Sensitivity low even in less extreme imbalanced data for 0.5 cutoff
- Costs are unknown

## Conclusion

I don't really see any value in sampling, but I'm not sure I should say that, or if I should still give some credit to sampling? (in one or two instances it had lower coefficients or slightly higher accuracy/AUC but it seems insignificant and variable to me)

- When costs are known, these approaches may be used with more intentional decision making

- Further Investigation:
  - Choosing cutoff with training set rather than test set




## Acknowledgments

Thesis Adviser Katie Colborn, thank you for all your time and mentoring

Committee members Elizabeth Juarez-Colunga and Susan Calcaterra, thank you for your time and expertise

Funding??

Thank you for attending.



## Case Study 1

- Design: Denver Health retrospective analysis electronic health record (EHR) data from 2008 to 2014.

- Patients: Hospitalized patients at an urban, safety-net hospital.

- Definition of Chronic Opioid Therapy (COT) one year following the index hospital discharge:

> Receipt of $\geq$ 90-day supply of opioids with < 30-day gap in supply over a 180-day period or receipt of $\geq$ 10 opioid prescriptions over one year. 



## Case Study 1: Patient Population 

- 27,705 patients
- Majority had incomes <185% of the Federal Poverty Level
- 70% were ethnic minorities
- 5% with COT

- Excluded Patients:
    - <15 or >85 years old
    - Those in prison, jail, or police custody
    - Those who died within one year following their index hospitalization
    - Patients with <2 healthcare visits to Denver Health three years preceding their index hospitalization
    - Undocumented persons receiving emergent hemodialysis
    - Obstetric patients
    
    
## Case Study 2

Add more details on this case study here

